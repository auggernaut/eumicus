Eumicus is an AI-assisted adaptive learning tool that helps you learn new concepts by adapting to what you already know.

üß† Product Requirements Document (PRD)

MVP: Local AI-Assisted Adaptive Learning Prototype (Vanilla, Offline-Friendly)

Date: October 2025
Owner: [Your Name / Team]
Version: 1.2 (Local MVP)

‚∏ª

1. üéØ Overview

This MVP is a local-first AI learning prototype that adapts to what the learner already knows using a simple local memory.json file as persistent context.

It‚Äôs designed to run entirely on your laptop with minimal dependencies ‚Äî no authentication, no database, no hosting ‚Äî just a lightweight web UI and OpenAI API calls.

The goal is to prove that an AI can:
	‚Ä¢	Read a user‚Äôs existing ‚Äúknowledge base,‚Äù
	‚Ä¢	Plan a short, tailored learning path,
	‚Ä¢	Teach a mini-lesson, quiz, and reflect,
	‚Ä¢	And update the user‚Äôs memory ‚Äî all in one run.

‚∏ª

2. üí° Problem

AI tutors are powerful but forgetful.
Each chat starts over; they don‚Äôt remember what you know or what you‚Äôve learned before.

Learners need a companion that builds on past learning and connects new ideas to old ones ‚Äî a tutor with continuity.

‚∏ª

3. üå± Solution Summary

A local app that runs this full loop:
	1.	Ask what you want to learn
	2.	Read your local memory (past concepts + reflections)
	3.	Plan a personalized mini-curriculum
	4.	Teach one topic interactively
	5.	Quiz and provide feedback
	6.	Reflect with you
	7.	Update the memory file with new insights

Everything runs in a single linear script ‚Äî no cloud infrastructure.

‚∏ª

4. ‚öôÔ∏è Architecture Overview

High-Level Flow

User goal
  ‚Üì
memory.json ‚Üí profile ‚Üí plan ‚Üí teach ‚Üí quiz ‚Üí reflect ‚Üí update memory

Each step is a small, testable function that:
	‚Ä¢	Takes the current context (goal, memory, results)
	‚Ä¢	Calls OpenAI‚Äôs API with a tailored prompt
	‚Ä¢	Returns a JSON or text result
	‚Ä¢	Logs its step to the console

No frameworks, queues, or multi-agent runtime ‚Äî just sequential execution.

‚∏ª

5. üß± Feature Scope

Module	Purpose	Implementation
Memory Loader / Writer	Reads & writes memory.json	Node fs module
Profiler	Summarizes known concepts & confidence levels	LLM prompt + JSON output
Planner	Creates 3‚Äì4 tailored subtopics to learn next	LLM prompt
Tutor	Generates an explainer/lesson in conversational tone	LLM completion
Quiz Generator	Produces 3‚Äì5 questions from lesson	LLM completion
Grader	Scores user answers, explains errors	LLM evaluation
Reflection Prompter	Guides learner to connect new insights	LLM prompt
Assimilator	Updates memory.json with new concepts/reflections	Node fs write


‚∏ª

6. üß≠ User Flow
	1.	Start the program ‚Üí CLI or minimal web UI opens.
	2.	Input a learning goal (e.g., ‚Äúlearn the basics of neural networks‚Äù).
	3.	Profiler scans memory and identifies known concepts.
	4.	Planner proposes 3‚Äì4 subtopics.
	5.	Tutor teaches the first topic in simple, interactive language.
	6.	Quiz Generator outputs 3‚Äì5 questions ‚Üí user answers in CLI or UI.
	7.	Grader provides immediate feedback.
	8.	Reflection Prompter asks a few guided questions (‚ÄúHow does this connect to what you already know?‚Äù).
	9.	Assimilator writes reflection + new knowledge into memory.json.
	10.	Console displays summary of what changed in memory.

‚∏ª

7. üß† Data Model

memory.json

{
  "concepts": [
    { "name": "linear algebra", "confidence": 0.9 },
    { "name": "gradient descent", "confidence": 0.5 }
  ],
  "reflections": [
    { "date": "2025-10-20", "text": "I realized how loss functions guide optimization." }
  ]
}

session.json (temporary runtime)

{
  "goal": "learn neural networks",
  "plan": ["Perceptrons", "Activation functions", "Backpropagation"],
  "lesson": "A neural network is a collection of...",
  "quiz": [{ "q": "...", "a": "..." }],
  "score": 4,
  "reflection": "It connects to my previous understanding of gradient descent."
}


‚∏ª

8. üíª Tech Stack

Layer	Technology
Runtime	Node.js (18+)
AI Model	OpenAI GPT-4o or GPT-4-turbo
Interface (optional)	CLI (Inquirer.js) or lightweight HTML page with local server
File I/O	Node fs
Persistence	Local JSON files only
Logging	Console output + optional log file


‚∏ª

9. üîÅ Execution Pipeline (Pseudocode)

async function main() {
  const goal = await askUser("What do you want to learn?");
  const memory = await loadMemory();
  const profile = await profileMemory(memory);
  const plan = await planCurriculum(goal, profile);
  const lesson = await teachLesson(plan[0]);
  const quiz = await generateQuiz(lesson);
  const answers = await askUserForAnswers(quiz);
  const graded = await gradeQuiz(quiz, answers);
  const reflection = await promptReflection(lesson, graded, memory);
  await updateMemory(memory, plan, reflection);
  console.log("Session complete! Memory updated.");
}

Each helper function simply calls the OpenAI API or reads/writes local files.

‚∏ª

10. üé® User Interface Options
	‚Ä¢	Option A (CLI-first)
	‚Ä¢	Runs via npm start
	‚Ä¢	Interactive Q&A in the terminal using Inquirer.js
	‚Ä¢	Logs results to session.json
	‚Ä¢	Option B (Local Web)
	‚Ä¢	Simple index.html served by Express or Next.js in dev mode
	‚Ä¢	Minimal input/output: goal ‚Üí chat window ‚Üí quiz ‚Üí reflection

‚∏ª

11. üìä Success Criteria

Metric	Description	Target
Full Run Completion	User reaches reflection + memory update	‚â• 90%
Session Time	Average 10‚Äì15 minutes per learning goal	‚úî
New Concepts Added	‚â• 3 new concepts appended to memory	‚úî
Reflection Written	Reflection logged for each session	100%
Average Cost	<$0.25 per run (OpenAI API)	‚úî
Latency	<4s per LLM call	‚úî


‚∏ª

12. üîí Constraints & Risks
	‚Ä¢	Local-only persistence: memory.json can be deleted or overwritten easily.
	‚Ä¢	No multi-user support: Single local learner only.
	‚Ä¢	Limited evaluation: No way to verify real learning beyond quiz answers.
	‚Ä¢	LLM variability: Quiz or feedback quality depends on model output.
	‚Ä¢	No sandboxing: The app trusts the LLM outputs (mitigate with safe JSON parsing).

‚∏ª

13. üöÄ Roadmap After MVP

Version	Goal	Additions
v1.1	Persistence & cloud backup	Add Firestore or local SQLite
v1.2	Pluggable memory	Integrate MCP (CORE, Mem0)
v1.3	Reflection analytics	Visualize concept graph
v2.0	Multi-user & peer learning	Add auth + shared lessons


‚∏ª

14. ‚ú® Product Philosophy

This MVP exists to prove one thing:

AI can teach reflectively, not just answer questions.

By storing and reusing even the simplest local memory, we begin to emulate how humans truly learn ‚Äî connecting new insights to what we already know.

‚ÄúThe real measure of intelligence isn‚Äôt recall ‚Äî it‚Äôs reflection.‚Äù

‚∏ª

